---
title: "A Personalized Acoustic Interface for Wearable Human–Machine Interaction"
authors:
- Z. Lin
- G. Zhang
- admin
- C. Au
- Y. Zhou
- C. Sun
- Z. Zhou
- R. Yan
- E. Fan
- S. Si
- L. Weng 
- S. Mathur
- J. Yang*
- J. Chen*
author_notes:
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- ""
- "Corresponding Author"
- "Corresponding Author"
date: "2021-11-20T00:00:00Z"
doi: "https://doi.org/10.1002/adfm.202109430"

# Schedule page publish date (NOT publication's date).
publishDate: "2021-11-20T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: "*Advanced Functional Materials*"
publication_short: "*Adv. Funct. Mater.*"

abstract: Communication and interaction with machines are changing our ways of life. However, developing an acoustic interface that simultaneously features waterproofness, wearability, high fidelity, and high accuracy for human–machine interaction remains a grand challenge. Herein, a waterproof acoustic sensor (WAS) as a wearable translation interface to communicate with machines is reported. Owing to the sound-response ability of internal microparticles, the WAS holds a significantly broad frequency response range of 0.1–20 kHz, covering almost the entire human audible range. The WAS is stable against human perspiration, shows omnidirectional response, and displays an excellent frequency detection resolution of 0.0001 kHz. With a collection of compelling features, the WAS can serve as a wearable acoustic human–machine interface and a high-fidelity auditory platform for music recording. Moreover, the WAS-based acoustic interface holds a remarkable 98% accuracy for speech recognition with the assistance of an artificial intelligence algorithm. Finally, the WAS-based acoustic interface demonstrates speaker verification and identification for implementation in highly secure biometric authentication systems and wireless control of an intelligent car using speech recognition. Such a WAS-based acoustic interface represents the advancement of high-fidelity translation platforms for human–machine interactions toward practical applications, including the Internet of Things, assistive technology, and intelligent recognition systems.
# Summary. An optional shortened abstract.
summary: A research article published in *Adv. Funct. Mater.*.

tags:
- acoustic sensor
- human-machine interface
- triboelectrification
featured: false

# links:
# - name: ""
#   url: ""
url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
  caption: 'Image credit: [****]()'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---
